{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_file(filepath: str):\n",
    "    return pd.read_json(filepath, orient=\"records\")\n",
    "\n",
    "df = read_file(\"data/obfuscated_data_06.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13613\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "with open('data/test_indices_2.txt', 'r') as file:\n",
    "    test_indices_2 = text_indices_2 = ast.literal_eval(file.read().strip())\n",
    "\n",
    "print(len(test_indices_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text              VISUALIZATION\\n\\nChallenge:\\n\\nAs a student (o...\n",
       "document                                                               0\n",
       "tokens                 [VISUALIZATION, \\n\\n, Challenge, :, \\n\\n, As, ...\n",
       "trailing_whitespace    [False, False, False, False, False, True, True...\n",
       "labels                 [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50661491\n"
     ]
    }
   ],
   "source": [
    "num_char = 0\n",
    "for i in range (len(df)):\n",
    "    if df.iloc[i].document in test_indices_2:\n",
    "        num_char += len(df.iloc[i].full_text)\n",
    "print(num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 16746176\n"
     ]
    }
   ],
   "source": [
    "total_tokens = sum(len(df.iloc[i].tokens) for i in range(len(df)))\n",
    "\n",
    "print(f\"Total number of tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in test set: 10051912\n"
     ]
    }
   ],
   "source": [
    "total_tokens_test = sum(len(df.iloc[i].tokens) for i in range(len(df)) if df.iloc[i].document in test_indices_2)\n",
    "\n",
    "print(f\"Total number of tokens in test set: {total_tokens_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 16746176\n"
     ]
    }
   ],
   "source": [
    "total_tokens = sum(len(df.iloc[i].tokens) for i in range(len(df)))\n",
    "\n",
    "print(f\"Total number of tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total cost (GPT-4o): $334.92\n",
      "Estimated total cost (GPT-4o-mini): $12.56\n"
     ]
    }
   ],
   "source": [
    "# Cost per token in dollars (GPT-4o)\n",
    "input_cost_per_token_gpt4o = 5 / 1000000  # Cost per input token\n",
    "output_cost_per_token_gpt4o = 15 / 1000000  # Cost per output token\n",
    "\n",
    "# Cost per token in dollars (GPT-4o-mini)\n",
    "input_cost_per_token_gpt4omini = 0.15 / 1000000  # Cost per input token\n",
    "output_cost_per_token_gpt4omini = 0.6 / 1000000  # Cost per output token\n",
    "\n",
    "# Calculate the total cost\n",
    "total_cost_gpt4o = total_tokens * (input_cost_per_token_gpt4o + output_cost_per_token_gpt4o)\n",
    "total_cost_gpt4omini = total_tokens * (input_cost_per_token_gpt4omini + output_cost_per_token_gpt4omini)\n",
    "\n",
    "print(f\"Estimated total cost (GPT-4o): ${total_cost_gpt4o:.2f}\")\n",
    "print(f\"Estimated total cost (GPT-4o-mini): ${total_cost_gpt4omini:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider Azure AI as baseline**\n",
    "Model performance first\n",
    "Efficiency (average time to process one transcript and show the length of each transcript),\n",
    "cost ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1380147\n",
      "Estimated cost for GPT-4o: $34.50\n",
      "Estimated cost for GPT-4o-mini: $4.14\n",
      "\n",
      "Total tokens (25% training): 343543\n",
      "Estimated cost for GPT-4o (25% training): $8.59\n",
      "Estimated cost for GPT-4o-mini (25% training): $1.03\n"
     ]
    }
   ],
   "source": [
    "# Estimate Fine-tuning cost\n",
    "import json\n",
    "import tiktoken  # This library is for counting tokens, make sure you have it installed\n",
    "\n",
    "# Function to count tokens in a text using tiktoken\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Calculate total tokens in JSONL file\n",
    "def calculate_total_tokens_and_cost(jsonl_file_path, base_cost_per_million_tokens, epochs=1):\n",
    "    total_tokens = 0\n",
    "\n",
    "    with open(jsonl_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            \n",
    "            # Convert the conversation messages to a single string for token counting\n",
    "            conversation_text = \" \".join([message['content'] for message in data['messages']])\n",
    "            \n",
    "            # Count the number of tokens for each conversation\n",
    "            total_tokens += count_tokens(conversation_text)\n",
    "\n",
    "    # Calculate the estimated cost\n",
    "    estimated_cost = (base_cost_per_million_tokens / 1000000) * total_tokens * epochs\n",
    "\n",
    "    return total_tokens, estimated_cost\n",
    "\n",
    "# Constants for GPT-4o and GPT-4o-mini\n",
    "base_cost_per_million_tokens_gpt4o = 25\n",
    "base_cost_per_million_tokens_gpt4o_mini = 3\n",
    "\n",
    "# Path to your JSONL file\n",
    "jsonl_file_path = 'output/pii_detected_all.jsonl'  # Replace with your actual file path\n",
    "jsonl_file_path_train = 'output/pii_detected_train.jsonl'  # Replace with your actual file path\n",
    "\n",
    "# Calculate tokens and costs for GPT-4o\n",
    "tokens_gpt4o, cost_gpt4o = calculate_total_tokens_and_cost(jsonl_file_path, base_cost_per_million_tokens_gpt4o)\n",
    "tokens_gpt4o_mini, cost_gpt4o_mini = calculate_total_tokens_and_cost(jsonl_file_path, base_cost_per_million_tokens_gpt4o_mini)\n",
    "\n",
    "tokens_gpt4o_train, cost_gpt4o_train = calculate_total_tokens_and_cost(jsonl_file_path_train, base_cost_per_million_tokens_gpt4o)\n",
    "tokens_gpt4o_mini_train, cost_gpt4o_mini_train = calculate_total_tokens_and_cost(jsonl_file_path_train, base_cost_per_million_tokens_gpt4o_mini)\n",
    "\n",
    "print(f\"Total tokens: {tokens_gpt4o}\")\n",
    "print(f\"Estimated cost for GPT-4o: ${cost_gpt4o:.2f}\")\n",
    "print(f\"Estimated cost for GPT-4o-mini: ${cost_gpt4o_mini:.2f}\\n\")\n",
    "\n",
    "print(f\"Total tokens (25% training): {tokens_gpt4o_train}\")\n",
    "print(f\"Estimated cost for GPT-4o (25% training): ${cost_gpt4o_train:.2f}\")\n",
    "print(f\"Estimated cost for GPT-4o-mini (25% training): ${cost_gpt4o_mini_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.902200999999998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8634067/1000000 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.902200999999998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6634067/1000000 * 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
