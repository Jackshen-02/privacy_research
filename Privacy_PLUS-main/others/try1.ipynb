{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuntianshen/Desktop/College/Research/privacy_research/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 94846.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>: O\n",
      "ĠPatient: O\n",
      "ĠJohn: B-PATIENT\n",
      "ĠDoe: L-PATIENT\n",
      "Ġwas: O\n",
      "Ġadmitted: O\n",
      "Ġto: O\n",
      "Ġthe: O\n",
      "Ġhospital: O\n",
      "Ġon: O\n",
      "Ġ12: B-DATE\n",
      "th: I-DATE\n",
      "ĠJuly: I-DATE\n",
      "Ġ2020: L-DATE\n",
      ".: O\n",
      "</s>: O\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "transformers_model = \"obi/deid_roberta_i2b2\"  # Example model for de-identification\n",
    "\n",
    "# Download the model snapshot\n",
    "snapshot_download(repo_id=transformers_model)\n",
    "\n",
    "# Instantiate tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformers_model)\n",
    "model = AutoModelForTokenClassification.from_pretrained(transformers_model)\n",
    "\n",
    "# Example text\n",
    "text = \"Patient John Doe was admitted to the hospital on 12th July 2020.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_token_class_ids = logits.argmax(-1).squeeze().tolist()\n",
    "\n",
    "# Map predicted token class IDs to labels\n",
    "predicted_labels = [model.config.id2label[id] for id in predicted_token_class_ids]\n",
    "\n",
    "# Print tokens with corresponding labels\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f\"{token}: {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
