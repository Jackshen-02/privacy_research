{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3701</td>\n",
       "      <td>Newton</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>3701</td>\n",
       "      <td>Newton</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>4553</td>\n",
       "      <td>Jessie Belal https://www.kramer.info/wp-conten...</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>4820</td>\n",
       "      <td>Moin Ch</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>6849</td>\n",
       "      <td>Madison Tate 034626995785</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>10269</td>\n",
       "      <td>Sergio Echavarria</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>10950</td>\n",
       "      <td>Matt Riley 201375864478</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>12640</td>\n",
       "      <td>https://youtu.be/uDRN9IA2T5</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>13735</td>\n",
       "      <td>No Bernardo</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>13735</td>\n",
       "      <td>No Bernardo</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>14108</td>\n",
       "      <td>Fortuna</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>14108</td>\n",
       "      <td>Fortuna</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>15904</td>\n",
       "      <td>Viviane Peeters benjamintaylor@hotmail.com 001...</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>16435</td>\n",
       "      <td>madehttps://smith.org/main/list/tagsprivacy.htm</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>19254</td>\n",
       "      <td>Jack</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>19360</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>20174</td>\n",
       "      <td>Zubair Khan</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>20301</td>\n",
       "      <td>Om Saleem</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_idx                                        entity_text  \\\n",
       "479       3701                                             Newton   \n",
       "480       3701                                             Newton   \n",
       "674       4553  Jessie Belal https://www.kramer.info/wp-conten...   \n",
       "711       4820                                            Moin Ch   \n",
       "1492      6849                          Madison Tate 034626995785   \n",
       "2456     10269                                  Sergio Echavarria   \n",
       "2610     10950                            Matt Riley 201375864478   \n",
       "4201     12640                        https://youtu.be/uDRN9IA2T5   \n",
       "4543     13735                                        No Bernardo   \n",
       "4544     13735                                        No Bernardo   \n",
       "5188     14108                                            Fortuna   \n",
       "5189     14108                                            Fortuna   \n",
       "5792     15904  Viviane Peeters benjamintaylor@hotmail.com 001...   \n",
       "6167     16435    madehttps://smith.org/main/list/tagsprivacy.htm   \n",
       "7213     19254                                               Jack   \n",
       "7235     19360                                               \\n\\n   \n",
       "7581     20174                                        Zubair Khan   \n",
       "7760     20301                                          Om Saleem   \n",
       "\n",
       "              type  \n",
       "479   NAME_STUDENT  \n",
       "480   NAME_STUDENT  \n",
       "674   NAME_STUDENT  \n",
       "711   NAME_STUDENT  \n",
       "1492  NAME_STUDENT  \n",
       "2456  NAME_STUDENT  \n",
       "2610  NAME_STUDENT  \n",
       "4201  URL_PERSONAL  \n",
       "4543  NAME_STUDENT  \n",
       "4544  NAME_STUDENT  \n",
       "5188  NAME_STUDENT  \n",
       "5189  NAME_STUDENT  \n",
       "5792  NAME_STUDENT  \n",
       "6167  URL_PERSONAL  \n",
       "7213  NAME_STUDENT  \n",
       "7235  NAME_STUDENT  \n",
       "7581  NAME_STUDENT  \n",
       "7760  NAME_STUDENT  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_undetected_entities(ground_truth_df, detected_data, azure_mapping, presidio_mapping):\n",
    "    \"\"\"\n",
    "    Find PII entities in the ground truth that are not detected by any of the models.\n",
    "    \n",
    "    Parameters:\n",
    "    - ground_truth_df (pd.DataFrame): The dataframe with true PII entities.\n",
    "    - detected_data (dict of pd.DataFrame): Dictionary with filenames as keys and detected dataframes as values.\n",
    "    - azure_mapping (dict): Mapping for Azure-detected entity types to ground truth types.\n",
    "    - presidio_mapping (dict): Mapping for Presidio-detected entity types to ground truth types.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe of true PII entities not detected by any model.\n",
    "    \"\"\"\n",
    "    # Apply type mappings to detected dataframes based on the source\n",
    "    for filename, detected_df in detected_data.items():\n",
    "        if 'azure' in filename.lower():  # Apply Azure mapping\n",
    "            detected_df['type'] = detected_df['type'].map(azure_mapping).fillna(detected_df['type'])\n",
    "        elif 'lg' in filename.lower() or 'trf' in filename.lower():  # Apply Presidio mapping\n",
    "            detected_df['type'] = detected_df['type'].map(presidio_mapping).fillna(detected_df['type'])\n",
    "        # Other models need no mapping adjustments\n",
    "\n",
    "    # Combine all detected entities across models\n",
    "    all_detected = pd.concat(detected_data.values())\n",
    "    all_detected = all_detected.drop_duplicates(subset=['file_idx', 'entity_text', 'type', 'positions'])\n",
    "    all_detected = all_detected.drop(columns=['positions'])\n",
    "    ground_truth_df = ground_truth_df.drop(columns=['positions'])\n",
    "\n",
    "    # Perform anti-join to find entities in ground truth not detected by any model\n",
    "    undetected_entities = ground_truth_df.merge(\n",
    "        all_detected, \n",
    "        # on=['file_idx', 'entity_text', 'type', 'positions'], \n",
    "        on=['file_idx', 'entity_text', 'type'], \n",
    "        how='left', \n",
    "        indicator=True\n",
    "    )\n",
    "    undetected_entities = undetected_entities[undetected_entities['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "    return undetected_entities\n",
    "\n",
    "# Load the dataframes and store them in a dictionary\n",
    "ground_truth = pd.read_csv('data/test_set_2.csv')\n",
    "\n",
    "# Dictionary of detected dataframes with filenames as keys\n",
    "detected_data = {\n",
    "    'pii_pre_lg_detected_2.csv': pd.read_csv('output/pii_pre_lg_detected_2.csv'),\n",
    "    'pii_detected_trf_2.csv': pd.read_csv('output/pii_detected_trf_2.csv'),\n",
    "    'pii_azure_detected.csv': pd.read_csv('output/pii_azure_detected.csv'),\n",
    "    'pii_pt_detected_2.csv': pd.read_csv('output/pii_pt_detected_2.csv'),\n",
    "    'pii_ft_detected_2.csv': pd.read_csv('output/pii_ft_detected_2.csv'),\n",
    "    'pii_ft_detected_ncot.csv': pd.read_csv('output/pii_ft_detected_ncot.csv'),\n",
    "    'pii_ft_detected_cot1.csv': pd.read_csv('output/pii_ft_detected_cot1.csv'),\n",
    "    'pii_ft_detected_cot2.csv': pd.read_csv('output/pii_ft_detected_cot2.csv')\n",
    "}\n",
    "\n",
    "# Define mappings\n",
    "azure_mapping = {\n",
    "    \"Person\": \"NAME_STUDENT\",\n",
    "    \"Email\": \"EMAIL\",\n",
    "    \"URL\": \"URL_PERSONAL\",\n",
    "    \"PhoneNumber\": \"PHONE_NUM\"\n",
    "}\n",
    "presidio_mapping = {\n",
    "    \"PERSON\": \"NAME_STUDENT\",\n",
    "    \"EMAIL_ADDRESS\": \"EMAIL\",\n",
    "    \"URL\": \"URL_PERSONAL\",\n",
    "    \"PHONE_NUMBER\": \"PHONE_NUM\"\n",
    "}\n",
    "\n",
    "# Get undetected entities\n",
    "undetected_entities = get_undetected_entities(\n",
    "    ground_truth,\n",
    "    detected_data,\n",
    "    azure_mapping,\n",
    "    presidio_mapping\n",
    ")\n",
    "\n",
    "# Save or inspect the results\n",
    "# undetected_entities.to_csv('output/undetected_entities.csv', index=False)\n",
    "print(undetected_entities.shape)\n",
    "undetected_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.read_csv('output/pii_ft_detected_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path = 'data/obfuscated_data_06.json'):\n",
    "    df = pd.read_json(path, orient=\"records\",encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "df = read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Matt', 'Riley', '201375864478', 'Cs-03']\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-ID_NUM', 'O']\n",
      "Matt Riley\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[10950].tokens[215:219])\n",
    "print(df.iloc[10950].labels[215:219])\n",
    "print(df.iloc[10950].full_text[1074:1084])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Viviane', 'Peeters', 'benjamintaylor@hotmail.com', '001', '-', '459', '-', '970', '-', '5605x7709', 'https://www.linkedin.com/in/fstone', '\\n\\n']\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-EMAIL', 'B-PHONE_NUM', 'I-PHONE_NUM', 'I-PHONE_NUM', 'I-PHONE_NUM', 'I-PHONE_NUM', 'I-PHONE_NUM', 'I-PHONE_NUM', 'B-URL_PERSONAL', 'O']\n",
      "Viviane Peeters benjamintaylor@hotmail.com 001-459-970-5605x7709 https://www.linkedin.com/in/fstone\n",
      "Viviane Peeters\n",
      "benjamintaylor@hotmail.com\n",
      "001-459-970-5605x7709\n",
      "https://www.linkedin.com/in/fstone\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[15904].tokens[1576:])\n",
    "print(df.iloc[15904].labels[1576:])\n",
    "print(df.iloc[15904].full_text[8432:8531])\n",
    "print(df.iloc[15904].full_text[8432:8447])\n",
    "print(df.iloc[15904].full_text[8448:8474])\n",
    "print(df.iloc[15904].full_text[8475:8496])\n",
    "print(df.iloc[15904].full_text[8497:8531])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Madison', 'Tate', '034626995785', '\\n\\n']\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-ID_NUM', 'O']\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[19254].labels\n",
    "print(df.iloc[6849].tokens[14:18])\n",
    "print(df.iloc[6849].labels[14:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('data/test_set_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jessie', 'Belal', 'https://www.kramer.info/wp-content/category/bloghome.php', '\\n\\n']\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-URL_PERSONAL', 'O']\n",
      "Jessie Belal\n",
      "https://www.kramer.info/wp-content/category/bloghome.php\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[4553].tokens[21:25])\n",
    "print(df.iloc[4553].labels[21:25])\n",
    "print(df.iloc[4553].full_text[119:131])\n",
    "print(df.iloc[4553].full_text[132:188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.johnson.biz/wp-content/appcategory.php', '>']\n",
      "['B-URL_PERSONAL', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[12267].tokens[648:650])\n",
    "print(df.iloc[12267].labels[648:650])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>type</th>\n",
       "      <th>positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>12267</td>\n",
       "      <td>Fazal Magdy</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(72, 83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>12267</td>\n",
       "      <td>https://www.johnson.biz/wp-content/appcategory...</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(3127, 3177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>12267</td>\n",
       "      <td>https://www.johnson.biz/wp-content/appcategory...</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(4706, 4756)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_idx                                        entity_text  \\\n",
       "2569     12267                                        Fazal Magdy   \n",
       "2570     12267  https://www.johnson.biz/wp-content/appcategory...   \n",
       "2571     12267  https://www.johnson.biz/wp-content/appcategory...   \n",
       "\n",
       "              type     positions  \n",
       "2569  NAME_STUDENT      (72, 83)  \n",
       "2570  URL_PERSONAL  (3127, 3177)  \n",
       "2571  URL_PERSONAL  (4706, 4756)  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft[df_ft['file_idx'] == 12267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>type</th>\n",
       "      <th>positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(2254, 2265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>16435</td>\n",
       "      <td>https://smith.org/main/list/tagsprivacy.htm</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(3585, 3628)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(4651, 4662)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(5000, 5011)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_idx                                  entity_text          type  \\\n",
       "3564     16435                                  Maniam Mani  NAME_STUDENT   \n",
       "3565     16435  https://smith.org/main/list/tagsprivacy.htm  URL_PERSONAL   \n",
       "3566     16435                                  Maniam Mani  NAME_STUDENT   \n",
       "3567     16435                                  Maniam Mani  NAME_STUDENT   \n",
       "\n",
       "         positions  \n",
       "3564  (2254, 2265)  \n",
       "3565  (3585, 3628)  \n",
       "3566  (4651, 4662)  \n",
       "3567  (5000, 5011)  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft[df_ft['file_idx'] == 16435]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>type</th>\n",
       "      <th>positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(2254, 2265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(4651, 4662)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>16435</td>\n",
       "      <td>Maniam Mani</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(5000, 5011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>16435</td>\n",
       "      <td>madehttps://smith.org/main/list/tagsprivacy.htm</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(3581, 3628)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_idx                                      entity_text          type  \\\n",
       "2186     16435                                      Maniam Mani  NAME_STUDENT   \n",
       "2187     16435                                      Maniam Mani  NAME_STUDENT   \n",
       "2188     16435                                      Maniam Mani  NAME_STUDENT   \n",
       "2189     16435  madehttps://smith.org/main/list/tagsprivacy.htm  URL_PERSONAL   \n",
       "\n",
       "         positions  \n",
       "2186  (2254, 2265)  \n",
       "2187  (4651, 4662)  \n",
       "2188  (5000, 5011)  \n",
       "2189  (3581, 3628)  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth[df_truth['file_idx'] == 16435]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reflection',\n",
       " ':',\n",
       " 'Story',\n",
       " 'Telling',\n",
       " '\\n\\n',\n",
       " 'A',\n",
       " 'Tool',\n",
       " 'to',\n",
       " 'Drive',\n",
       " 'Social',\n",
       " 'Change',\n",
       " '\\n\\n',\n",
       " 'Challenge',\n",
       " ':',\n",
       " '\\n\\n',\n",
       " 'I',\n",
       " 'work',\n",
       " 'with',\n",
       " 'companies',\n",
       " 'in',\n",
       " 'Saudi',\n",
       " 'Arabia',\n",
       " 'which',\n",
       " 'have',\n",
       " 'an',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'driving',\n",
       " 'social',\n",
       " 'change',\n",
       " 'through',\n",
       " ' ',\n",
       " 'their',\n",
       " 'social',\n",
       " 'responsibility',\n",
       " 'departments',\n",
       " '.',\n",
       " 'Such',\n",
       " 'sector',\n",
       " 'in',\n",
       " 'Saudi',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'new',\n",
       " 'and',\n",
       " 'is',\n",
       " 'slowly',\n",
       " ' ',\n",
       " 'complementing',\n",
       " 'the',\n",
       " 'work',\n",
       " 'of',\n",
       " 'marketing',\n",
       " 'departments',\n",
       " '.',\n",
       " 'The',\n",
       " 'main',\n",
       " 'challenge',\n",
       " 'was',\n",
       " 'complex',\n",
       " 'as',\n",
       " 'many',\n",
       " ' ',\n",
       " 'of',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'were',\n",
       " 'either',\n",
       " 'misunderstanding',\n",
       " 'social',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'charity',\n",
       " 'or',\n",
       " 'ﬁguring',\n",
       " 'their',\n",
       " 'way',\n",
       " ' ',\n",
       " 'through',\n",
       " 'it',\n",
       " 'as',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'new',\n",
       " 'ﬁeld',\n",
       " ',',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'convince',\n",
       " 'their',\n",
       " 'managers',\n",
       " 'to',\n",
       " 'spend',\n",
       " 'more',\n",
       " 'budget',\n",
       " 'on',\n",
       " 'it',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'For',\n",
       " 'the',\n",
       " 'uneducated',\n",
       " 'client',\n",
       " ',',\n",
       " 'the',\n",
       " 'road',\n",
       " 'was',\n",
       " 'longer',\n",
       " 'as',\n",
       " 'we',\n",
       " 'needed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'education',\n",
       " 'before',\n",
       " ' ',\n",
       " 'expecting',\n",
       " 'the',\n",
       " 'client',\n",
       " 'to',\n",
       " 'embrace',\n",
       " 'any',\n",
       " 'of',\n",
       " 'our',\n",
       " 'services',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'The',\n",
       " 'easier',\n",
       " 'challenge',\n",
       " 'was',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'the',\n",
       " 'educated',\n",
       " 'client',\n",
       " 'to',\n",
       " 'help',\n",
       " 'them',\n",
       " 'tell',\n",
       " 'compelling',\n",
       " 'stories',\n",
       " 'to',\n",
       " ' ',\n",
       " 'their',\n",
       " 'management',\n",
       " 'and',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'starting',\n",
       " 'to',\n",
       " 'create',\n",
       " 'new',\n",
       " 'social',\n",
       " 'initiatives',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'We',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'helping',\n",
       " 'the',\n",
       " 'educated',\n",
       " 'client',\n",
       " 'tell',\n",
       " 'their',\n",
       " 'management',\n",
       " 'better',\n",
       " 'stories',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Selection',\n",
       " ':',\n",
       " '\\n\\n',\n",
       " 'The',\n",
       " 'tool',\n",
       " 'we',\n",
       " 'selected',\n",
       " 'was',\n",
       " 'story',\n",
       " 'telling',\n",
       " '.',\n",
       " 'Story',\n",
       " 'telling',\n",
       " 'was',\n",
       " 'n’t',\n",
       " 'only',\n",
       " 'helping',\n",
       " 'us',\n",
       " 'crack',\n",
       " 'open',\n",
       " 'exciting',\n",
       " ' ',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'story',\n",
       " 'that',\n",
       " 'the',\n",
       " 'client',\n",
       " 'did',\n",
       " 'not',\n",
       " 'see',\n",
       " '(',\n",
       " 'since',\n",
       " 'they',\n",
       " 'were',\n",
       " 'concerned',\n",
       " 'about',\n",
       " 'how',\n",
       " 'much',\n",
       " 'they',\n",
       " 'will',\n",
       " ' ',\n",
       " 'be',\n",
       " 'spending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'project',\n",
       " ')',\n",
       " '.',\n",
       " 'Story',\n",
       " 'telling',\n",
       " 'made',\n",
       " 'it',\n",
       " 'much',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'the',\n",
       " 'value',\n",
       " 'addition',\n",
       " ' ',\n",
       " 'that',\n",
       " 'the',\n",
       " 'project',\n",
       " 'brings',\n",
       " 'to',\n",
       " 'the',\n",
       " 'table',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Story',\n",
       " 'telling',\n",
       " 'helped',\n",
       " 'us',\n",
       " 'communicate',\n",
       " 'the',\n",
       " 'main',\n",
       " 'challenge',\n",
       " 'that',\n",
       " 'we',\n",
       " '’re',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'address',\n",
       " 'for',\n",
       " 'our',\n",
       " ' ',\n",
       " 'beneﬁciaries',\n",
       " ',',\n",
       " 'the',\n",
       " 'value',\n",
       " 'that',\n",
       " 'the',\n",
       " 'project',\n",
       " 'will',\n",
       " 'add',\n",
       " ',',\n",
       " 'how',\n",
       " 'success',\n",
       " 'of',\n",
       " 'the',\n",
       " 'project',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'and',\n",
       " 'how',\n",
       " ' ',\n",
       " 'we',\n",
       " 'expect',\n",
       " 'the',\n",
       " 'project',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sustained',\n",
       " 'and',\n",
       " 'how',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'self',\n",
       " 'propelling',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'We',\n",
       " 'usually',\n",
       " 'used',\n",
       " 'two',\n",
       " 'main',\n",
       " 'tools',\n",
       " 'to',\n",
       " 'make',\n",
       " 'the',\n",
       " 'story',\n",
       " 'compelling',\n",
       " 'to',\n",
       " 'our',\n",
       " 'clients',\n",
       " ',',\n",
       " 'videos',\n",
       " 'and',\n",
       " 'power',\n",
       " ' ',\n",
       " 'point',\n",
       " 'presentations',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Application',\n",
       " ':',\n",
       " '\\n\\n',\n",
       " 'Story',\n",
       " 'telling',\n",
       " 'is',\n",
       " 'used',\n",
       " 'on',\n",
       " 'daily',\n",
       " 'bases',\n",
       " 'with',\n",
       " 'different',\n",
       " 'client',\n",
       " 'to',\n",
       " 'make',\n",
       " 'them',\n",
       " 'see',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'our',\n",
       " ' ',\n",
       " 'projects',\n",
       " 'and',\n",
       " 'initiatives',\n",
       " 'makes',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'It',\n",
       " 'is',\n",
       " 'used',\n",
       " 'in',\n",
       " 'every',\n",
       " 'day',\n",
       " 'meetings',\n",
       " 'but',\n",
       " 'most',\n",
       " 'importantly',\n",
       " 'in',\n",
       " 'proposals',\n",
       " 'we',\n",
       " 'provide',\n",
       " 'to',\n",
       " 'our',\n",
       " 'clients',\n",
       " '.',\n",
       " 'We',\n",
       " ' ',\n",
       " 'usually',\n",
       " 'would',\n",
       " 'start',\n",
       " 'by',\n",
       " 'describing',\n",
       " 'the',\n",
       " 'need',\n",
       " ',',\n",
       " 'the',\n",
       " 'bigger',\n",
       " 'cause',\n",
       " 'or',\n",
       " 'issue',\n",
       " 'we',\n",
       " '’re',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'solve',\n",
       " '.',\n",
       " 'We',\n",
       " 'then',\n",
       " ' ',\n",
       " 'move',\n",
       " 'into',\n",
       " 'describing',\n",
       " 'our',\n",
       " 'objectives',\n",
       " ',',\n",
       " 'target',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'success',\n",
       " 'looks',\n",
       " 'like',\n",
       " '.',\n",
       " 'We',\n",
       " 'then',\n",
       " ' ',\n",
       " 'describe',\n",
       " 'what',\n",
       " 'we',\n",
       " '’re',\n",
       " 'providing',\n",
       " 'to',\n",
       " 'address',\n",
       " 'the',\n",
       " 'challenge',\n",
       " ',',\n",
       " 'how',\n",
       " 'much',\n",
       " 'time',\n",
       " 'it',\n",
       " 'takes',\n",
       " 'to',\n",
       " 'implement',\n",
       " 'and',\n",
       " '\\n\\n',\n",
       " 'DESIGN',\n",
       " 'THINKING',\n",
       " ':',\n",
       " 'STORY',\n",
       " 'Maniam',\n",
       " 'Mani',\n",
       " '�',\n",
       " '1',\n",
       " '\\n\\n',\n",
       " 'how',\n",
       " 'much',\n",
       " 'it',\n",
       " 'costs',\n",
       " '.',\n",
       " 'We',\n",
       " 'always',\n",
       " 'provide',\n",
       " 'a',\n",
       " 'story',\n",
       " 'told',\n",
       " 'by',\n",
       " 'an',\n",
       " 'imagined',\n",
       " 'beneﬁciary',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'what',\n",
       " ' ',\n",
       " 'the',\n",
       " 'target',\n",
       " 'audiences',\n",
       " 'will',\n",
       " 'learn',\n",
       " ',',\n",
       " 'feel',\n",
       " ',',\n",
       " 'see',\n",
       " ',',\n",
       " 'touch',\n",
       " 'and',\n",
       " 'smell',\n",
       " 'during',\n",
       " 'their',\n",
       " 'experience',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'For',\n",
       " 'instance',\n",
       " ',',\n",
       " 'story',\n",
       " 'telling',\n",
       " 'was',\n",
       " 'used',\n",
       " 'as',\n",
       " 'a',\n",
       " 'tool',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'why',\n",
       " 'we',\n",
       " 'need',\n",
       " 'more',\n",
       " 'women',\n",
       " 'signing',\n",
       " 'up',\n",
       " 'into',\n",
       " ' ',\n",
       " 'STEM',\n",
       " 'related',\n",
       " 'professions',\n",
       " '.',\n",
       " 'Starting',\n",
       " 'from',\n",
       " 'the',\n",
       " 'innovation',\n",
       " 'index',\n",
       " ',',\n",
       " 'how',\n",
       " 'Saudi',\n",
       " 'Arabia',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " '47th',\n",
       " ' ',\n",
       " 'position',\n",
       " 'world',\n",
       " 'wide',\n",
       " ',',\n",
       " 'how',\n",
       " 'women',\n",
       " 'are',\n",
       " 'around',\n",
       " '50',\n",
       " '%',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Saudi',\n",
       " 'population',\n",
       " ',',\n",
       " 'how',\n",
       " 'many',\n",
       " 'Saudi',\n",
       " ' ',\n",
       " 'young',\n",
       " 'girls',\n",
       " 'are',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ages',\n",
       " '12',\n",
       " '-',\n",
       " '18',\n",
       " 'and',\n",
       " 'how',\n",
       " 'engineering',\n",
       " 'and',\n",
       " 'science',\n",
       " 'are',\n",
       " 'among',\n",
       " 'the',\n",
       " 'professions',\n",
       " ' ',\n",
       " 'least',\n",
       " 'selected',\n",
       " 'by',\n",
       " 'women',\n",
       " 'in',\n",
       " 'Saudi',\n",
       " 'while',\n",
       " 'need',\n",
       " 'for',\n",
       " 'it',\n",
       " 'is',\n",
       " 'high',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Insight',\n",
       " ':',\n",
       " '\\n\\n',\n",
       " 'To',\n",
       " 'be',\n",
       " 'honest',\n",
       " ',',\n",
       " 'the',\n",
       " 'usage',\n",
       " 'of',\n",
       " 'story',\n",
       " 'telling',\n",
       " 'was',\n",
       " 'not',\n",
       " 'a',\n",
       " 'conscious',\n",
       " 'decision',\n",
       " 'we',\n",
       " 'made',\n",
       " 'until',\n",
       " 'recently',\n",
       " '.',\n",
       " ' ',\n",
       " 'What',\n",
       " 'we',\n",
       " 'started',\n",
       " 'noticing',\n",
       " 'is',\n",
       " 'that',\n",
       " 'clients',\n",
       " 'light',\n",
       " 'up',\n",
       " 'when',\n",
       " 'we',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'the',\n",
       " 'stories',\n",
       " 'of',\n",
       " 'students',\n",
       " 'we',\n",
       " ' ',\n",
       " 'worked',\n",
       " 'with',\n",
       " 'and',\n",
       " 'who',\n",
       " 'achieved',\n",
       " 'highly',\n",
       " 'in',\n",
       " 'their',\n",
       " 'lives',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'We',\n",
       " 'also',\n",
       " 'noticed',\n",
       " 'that',\n",
       " 'clients',\n",
       " 'loved',\n",
       " 'watching',\n",
       " 'previous',\n",
       " 'initiatives',\n",
       " 'videos',\n",
       " 'and',\n",
       " 'how',\n",
       " 'success',\n",
       " 'was',\n",
       " ' ',\n",
       " 'achieved',\n",
       " 'for',\n",
       " 'each',\n",
       " 'of',\n",
       " 'our',\n",
       " 'clients',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'We',\n",
       " 'then',\n",
       " 'noticed',\n",
       " 'that',\n",
       " 'proposals',\n",
       " 'that',\n",
       " 'told',\n",
       " 'a',\n",
       " 'story',\n",
       " 'and',\n",
       " 'anchored',\n",
       " 'the',\n",
       " 'why',\n",
       " 'questions',\n",
       " 'well',\n",
       " 'had',\n",
       " 'higher',\n",
       " ' ',\n",
       " 'chances',\n",
       " 'to',\n",
       " 'ﬂy',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'After',\n",
       " 'all',\n",
       " 'these',\n",
       " 'notes',\n",
       " ',',\n",
       " 'we',\n",
       " 'consciously',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'make',\n",
       " 'our',\n",
       " 'interaction',\n",
       " 'with',\n",
       " 'clients',\n",
       " '-including',\n",
       " ' ',\n",
       " 'proposals-',\n",
       " 'based',\n",
       " 'on',\n",
       " 'story',\n",
       " 'telling',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'of',\n",
       " 'a',\n",
       " 'video',\n",
       " 'we',\n",
       " 'created',\n",
       " 'for',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'initiatives',\n",
       " 'we',\n",
       " 'madehttps://smith.org/main/list/tagsprivacy.htm',\n",
       " '\\n\\n',\n",
       " 'Approach',\n",
       " ':',\n",
       " '\\n\\n',\n",
       " 'Our',\n",
       " 'approach',\n",
       " 'got',\n",
       " 'polished',\n",
       " 'by',\n",
       " 'now',\n",
       " 'so',\n",
       " 'we',\n",
       " 'are',\n",
       " 'in',\n",
       " 'a',\n",
       " 'far',\n",
       " 'better',\n",
       " 'position',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'what',\n",
       " 'is',\n",
       " 'still',\n",
       " 'hard',\n",
       " ' ',\n",
       " 'to',\n",
       " 'master',\n",
       " 'is',\n",
       " 'the',\n",
       " 'time',\n",
       " 'that',\n",
       " 'understanding',\n",
       " 'each',\n",
       " 'client',\n",
       " 'case',\n",
       " 'and',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'with',\n",
       " 'a',\n",
       " 'great',\n",
       " 'story',\n",
       " 'to',\n",
       " ' ',\n",
       " 'help',\n",
       " 'them',\n",
       " 'address',\n",
       " 'their',\n",
       " 'challenge',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'In',\n",
       " 'many',\n",
       " 'cases',\n",
       " ',',\n",
       " 'we',\n",
       " 'resort',\n",
       " 'back',\n",
       " 'to',\n",
       " 'offering',\n",
       " 'similar',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'clients',\n",
       " 'with',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " ' ',\n",
       " 'customization',\n",
       " '.',\n",
       " 'When',\n",
       " 'a',\n",
       " 'client',\n",
       " 'with',\n",
       " 'totally',\n",
       " 'new',\n",
       " 'requirements',\n",
       " 'come',\n",
       " ',',\n",
       " 'creating',\n",
       " 'a',\n",
       " 'totally',\n",
       " 'new',\n",
       " 'solution',\n",
       " ' ',\n",
       " 'for',\n",
       " 'them',\n",
       " '(',\n",
       " 'even',\n",
       " 'if',\n",
       " 'its',\n",
       " 'just',\n",
       " 'a',\n",
       " 'draft',\n",
       " ')',\n",
       " 'becomes',\n",
       " 'time',\n",
       " 'and',\n",
       " 'resources',\n",
       " 'consuming',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Our',\n",
       " 'remedy',\n",
       " 'to',\n",
       " 'that',\n",
       " 'was',\n",
       " 'pushing',\n",
       " 'initial',\n",
       " 'draft',\n",
       " 'proposals',\n",
       " 'to',\n",
       " 'the',\n",
       " 'client',\n",
       " 'early',\n",
       " 'on',\n",
       " ',',\n",
       " 'where',\n",
       " 'they',\n",
       " '’re',\n",
       " 'able',\n",
       " 'to',\n",
       " ' ',\n",
       " 'discuss',\n",
       " ',',\n",
       " 'comment',\n",
       " 'and',\n",
       " 'feedback',\n",
       " 'quickly',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'the',\n",
       " 'closest',\n",
       " 'possible',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'their',\n",
       " ' ',\n",
       " 'requirements',\n",
       " '.',\n",
       " 'We',\n",
       " 'mostly',\n",
       " 'refrain',\n",
       " 'from',\n",
       " 'proposing',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'clients',\n",
       " 'in',\n",
       " 'the',\n",
       " 'proposal',\n",
       " 'stage',\n",
       " ',',\n",
       " 'we',\n",
       " ' ',\n",
       " 'instead',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'telling',\n",
       " 'them',\n",
       " 'the',\n",
       " 'best',\n",
       " 'story',\n",
       " 'they',\n",
       " 'could',\n",
       " 'hear',\n",
       " 'for',\n",
       " 'their',\n",
       " 'challenges',\n",
       " '.',\n",
       " 'Therefore',\n",
       " ',',\n",
       " 'we',\n",
       " ' ',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'describing',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'well',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'very',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'the',\n",
       " '“',\n",
       " 'what',\n",
       " 'is',\n",
       " '”',\n",
       " 'stage',\n",
       " 'in',\n",
       " 'design',\n",
       " ' ',\n",
       " 'thinking',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'DESIGN',\n",
       " 'THINKING',\n",
       " ':',\n",
       " 'STORY',\n",
       " 'Maniam',\n",
       " 'Mani',\n",
       " '�',\n",
       " '2',\n",
       " '\\n\\n',\n",
       " 'What',\n",
       " 'is',\n",
       " 'great',\n",
       " 'about',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'that',\n",
       " 'we',\n",
       " 'experimented',\n",
       " 'and',\n",
       " 'came',\n",
       " 'to',\n",
       " 'those',\n",
       " 'approaches',\n",
       " 'and',\n",
       " 'we',\n",
       " 'found',\n",
       " ' ',\n",
       " 'similar',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'it',\n",
       " 'in',\n",
       " 'design',\n",
       " 'thinking',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Story',\n",
       " 'telling',\n",
       " 'is',\n",
       " 'helping',\n",
       " 'us',\n",
       " 'in',\n",
       " 'great',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'how',\n",
       " 'their',\n",
       " 'success',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'and',\n",
       " 'as',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'result',\n",
       " 'it',\n",
       " 'is',\n",
       " 'improving',\n",
       " 'our',\n",
       " 'revenue',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'else',\n",
       " 'with',\n",
       " 'it',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'DESIGN',\n",
       " 'THINKING',\n",
       " ':',\n",
       " 'STORY',\n",
       " 'Maniam',\n",
       " 'Mani',\n",
       " '�',\n",
       " '3',\n",
       " '\\n\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[16435].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>type</th>\n",
       "      <th>positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>472</td>\n",
       "      <td>https://youtu.be/rFD2lJuvace</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(4886, 4914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>589</td>\n",
       "      <td>https://www.wagner.net/categoriesmain.jsp</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(2863, 2904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>761</td>\n",
       "      <td>https://www.youtube.com/watch?v=Kx0SXy87bVZ</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(1186, 1229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1798</td>\n",
       "      <td>http://www.burns-lopez.com/categories/appabout...</td>\n",
       "      <td>URL_PERSONAL</td>\n",
       "      <td>(1611, 1661)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3241</td>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(3156, 3165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>20507</td>\n",
       "      <td>Anand Patel</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(5694, 5705)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>21179</td>\n",
       "      <td>Ana Medina</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(5330, 5340)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>21321</td>\n",
       "      <td>Omar Iqbal</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(1656, 1666)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>21844</td>\n",
       "      <td>Mg Maurel</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(0, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>22166</td>\n",
       "      <td>Auwal De Maio</td>\n",
       "      <td>NAME_STUDENT</td>\n",
       "      <td>(38, 51)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_idx                                        entity_text  \\\n",
       "38         472                       https://youtu.be/rFD2lJuvace   \n",
       "40         589          https://www.wagner.net/categoriesmain.jsp   \n",
       "62         761        https://www.youtube.com/watch?v=Kx0SXy87bVZ   \n",
       "118       1798  http://www.burns-lopez.com/categories/appabout...   \n",
       "177       3241                                          Rodriguez   \n",
       "...        ...                                                ...   \n",
       "2768     20507                                        Anand Patel   \n",
       "2812     21179                                         Ana Medina   \n",
       "2833     21321                                         Omar Iqbal   \n",
       "2849     21844                                          Mg Maurel   \n",
       "2863     22166                                      Auwal De Maio   \n",
       "\n",
       "              type     positions  \n",
       "38    URL_PERSONAL  (4886, 4914)  \n",
       "40    URL_PERSONAL  (2863, 2904)  \n",
       "62    URL_PERSONAL  (1186, 1229)  \n",
       "118   URL_PERSONAL  (1611, 1661)  \n",
       "177   NAME_STUDENT  (3156, 3165)  \n",
       "...            ...           ...  \n",
       "2768  NAME_STUDENT  (5694, 5705)  \n",
       "2812  NAME_STUDENT  (5330, 5340)  \n",
       "2833  NAME_STUDENT  (1656, 1666)  \n",
       "2849  NAME_STUDENT        (0, 9)  \n",
       "2863  NAME_STUDENT      (38, 51)  \n",
       "\n",
       "[162 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_undetected_entities(ground_truth_df, detected_data, azure_mapping, presidio_mapping):\n",
    "    \"\"\"\n",
    "    Find PII entities in the ground truth that are not detected by any of the models.\n",
    "    \n",
    "    Parameters:\n",
    "    - ground_truth_df (pd.DataFrame): The dataframe with true PII entities.\n",
    "    - detected_data (dict of pd.DataFrame): Dictionary with filenames as keys and detected dataframes as values.\n",
    "    - azure_mapping (dict): Mapping for Azure-detected entity types to ground truth types.\n",
    "    - presidio_mapping (dict): Mapping for Presidio-detected entity types to ground truth types.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe of true PII entities not detected by any model.\n",
    "    \"\"\"\n",
    "    # Apply type mappings to detected dataframes based on the source\n",
    "    for filename, detected_df in detected_data.items():\n",
    "        if 'azure' in filename.lower():  # Apply Azure mapping\n",
    "            detected_df['type'] = detected_df['type'].map(azure_mapping).fillna(detected_df['type'])\n",
    "        elif 'lg' in filename.lower() or 'trf' in filename.lower():  # Apply Presidio mapping\n",
    "            detected_df['type'] = detected_df['type'].map(presidio_mapping).fillna(detected_df['type'])\n",
    "        # Other models need no mapping adjustments\n",
    "\n",
    "    # Combine all detected entities across models\n",
    "    all_detected = pd.concat(detected_data.values())\n",
    "    all_detected = all_detected.drop_duplicates(subset=['file_idx', 'entity_text', 'type', 'positions'])\n",
    "\n",
    "    # Perform anti-join to find entities in ground truth not detected by any model\n",
    "    undetected_entities = ground_truth_df.merge(\n",
    "        all_detected, \n",
    "        on=['file_idx', 'entity_text', 'type', 'positions'], \n",
    "        how='left', \n",
    "        indicator=True\n",
    "    )\n",
    "    undetected_entities = undetected_entities[undetected_entities['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "    return undetected_entities\n",
    "\n",
    "# Load the dataframes and store them in a dictionary\n",
    "ground_truth = pd.read_csv('data/test_set_2.csv')\n",
    "\n",
    "# Dictionary of detected dataframes with filenames as keys\n",
    "detected_data = {\n",
    "    # 'pii_pre_lg_detected_2.csv': pd.read_csv('output/pii_pre_lg_detected_2.csv'),\n",
    "    # 'pii_detected_trf_2.csv': pd.read_csv('output/pii_detected_trf_2.csv'),\n",
    "    # 'pii_azure_detected.csv': pd.read_csv('output/pii_azure_detected.csv'),\n",
    "    # 'pii_pt_detected_2.csv': pd.read_csv('output/pii_pt_detected_2.csv'),\n",
    "    'pii_ft_detected_2.csv': pd.read_csv('output/pii_ft_detected_2.csv'),\n",
    "    # 'pii_ft_detected_ncot.csv': pd.read_csv('output/pii_ft_detected_ncot.csv'),\n",
    "    # 'pii_ft_detected_cot1.csv': pd.read_csv('output/pii_ft_detected_cot1.csv'),\n",
    "    # 'pii_ft_detected_cot2.csv': pd.read_csv('output/pii_ft_detected_cot2.csv')\n",
    "}\n",
    "\n",
    "# Define mappings\n",
    "azure_mapping = {\n",
    "    \"Person\": \"NAME_STUDENT\",\n",
    "    \"Email\": \"EMAIL\",\n",
    "    \"URL\": \"URL_PERSONAL\",\n",
    "    \"PhoneNumber\": \"PHONE_NUM\"\n",
    "}\n",
    "presidio_mapping = {\n",
    "    \"PERSON\": \"NAME_STUDENT\",\n",
    "    \"EMAIL_ADDRESS\": \"EMAIL\",\n",
    "    \"URL\": \"URL_PERSONAL\",\n",
    "    \"PHONE_NUMBER\": \"PHONE_NUM\"\n",
    "}\n",
    "\n",
    "# Get undetected entities\n",
    "undetected_entities = get_undetected_entities(\n",
    "    ground_truth,\n",
    "    detected_data,\n",
    "    azure_mapping,\n",
    "    presidio_mapping\n",
    ")\n",
    "\n",
    "# Save or inspect the results\n",
    "# undetected_entities.to_csv('output/undetected_entities.csv', index=False)\n",
    "print(undetected_entities.shape)\n",
    "undetected_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lg = pd.read_csv('output/pii_pre_lg_detected_2.csv')\n",
    "pre_trf = pd.read_csv('output/pii_detected_trf_2.csv')\n",
    "azure = pd.read_csv('output/pii_azure_detected.csv')\n",
    "pt = pd.read_csv('output/pii_pt_detected_2.csv')\n",
    "ft = pd.read_csv('output/pii_ft_detected_2.csv')\n",
    "ncot = pd.read_csv('output/pii_ft_detected_ncot.csv')\n",
    "cot1 = pd.read_csv('output/pii_ft_detected_cot1.csv')\n",
    "cot2 = pd.read_csv('output/pii_ft_detected_cot2.csv')\n",
    "dataset_list = [pre_lg, pre_trf, azure, pt, ft, ncot, cot1, cot2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "def check_entity(entity, dataset_list):\n",
    "    res_lst = []\n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "        if entity in dataset['entity_text'].values:\n",
    "            res_lst.append(i)\n",
    "    return res_lst\n",
    "\n",
    "i = check_entity('Soka', dataset_list)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "i = check_entity('Jordi', dataset_list)\n",
    "print(i)\n",
    "# pre_trf, azure, ft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
