{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the test DataFrame\n",
    "df_test = pd.read_csv('output/pii_detected_test.csv')\n",
    "df_detected = pd.read_csv('output/pii_detected_trf_filtered.csv')\n",
    "df_true = pd.read_csv('data/pii_true_entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "TP: 3033, FP: 9472, FN: 1838\n",
      "Precision: 0.2425, Recall: 0.6227\n",
      "F1 Score: 0.3491, F5 Score: 0.5873\n",
      "\n",
      "Category: PERSON\n",
      "TP: 2721, FP: 8777, FN: 1673\n",
      "Precision: 0.2366, Recall: 0.6193\n",
      "F1 Score: 0.3424, F5 Score: 0.5830\n",
      "\n",
      "Category: URL\n",
      "TP: 219, FP: 626, FN: 133\n",
      "Precision: 0.2592, Recall: 0.6222\n",
      "F1 Score: 0.3659, F5 Score: 0.5904\n",
      "\n",
      "Category: PHONE_NUMBER\n",
      "TP: 10, FP: 53, FN: 4\n",
      "Precision: 0.1587, Recall: 0.7143\n",
      "F1 Score: 0.2597, F5 Score: 0.6295\n",
      "\n",
      "Category: EMAIL_ADDRESS\n",
      "TP: 83, FP: 16, FN: 28\n",
      "Precision: 0.8384, Recall: 0.7477\n",
      "F1 Score: 0.7905, F5 Score: 0.7509\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Mapping of category names from df_true to df_test\n",
    "# category_mapping = {\n",
    "#     'NAME_STUDENT': 'PERSON',\n",
    "#     'EMAIL': 'EMAIL_ADDRESS',\n",
    "#     'URL_PERSONAL': 'URL',\n",
    "#     'PHONE_NUM': 'PHONE_NUMBER'\n",
    "# }\n",
    "\n",
    "# def calculate_metrics(df_test, df_true):\n",
    "#     # Initialize counts\n",
    "#     overall_metrics = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "#     category_metrics = {}\n",
    "\n",
    "#     # Calculate TP and FP from df_test\n",
    "#     overall_metrics['TP'] = df_test[df_test['true_label'] == 'T'].shape[0]\n",
    "#     overall_metrics['FP'] = df_test[df_test['true_label'] == 'F'].shape[0]\n",
    "\n",
    "#     # Calculate FN by comparing df_true and df_test\n",
    "#     for _, true_row in df_true.iterrows():\n",
    "#         # Map the true category to the test category\n",
    "#         test_category = category_mapping[true_row['type']]\n",
    "        \n",
    "#         # Check if the true entity exists in the test dataset\n",
    "#         matched = df_test[(df_test['file_idx'] == true_row['file_idx']) &\n",
    "#                           (df_test['entity_text'] == true_row['entity_text']) &\n",
    "#                           (df_test['positions'] == true_row['positions']) &\n",
    "#                           (df_test['type'] == test_category)]\n",
    "#         if matched.empty:\n",
    "#             # If no match is found, it is a false negative\n",
    "#             overall_metrics['FN'] += 1\n",
    "#             if test_category not in category_metrics:\n",
    "#                 category_metrics[test_category] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "#             category_metrics[test_category]['FN'] += 1\n",
    "\n",
    "#     # Update category-wise TP and FP\n",
    "#     for _, test_row in df_test.iterrows():\n",
    "#         category = test_row['type']\n",
    "#         if category not in category_metrics:\n",
    "#             category_metrics[category] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "        \n",
    "#         if test_row['true_label'] == 'T':\n",
    "#             category_metrics[category]['TP'] += 1\n",
    "#         else:\n",
    "#             category_metrics[category]['FP'] += 1\n",
    "\n",
    "#     # Calculate overall precision, recall, F1, and F5 score\n",
    "#     overall_precision = overall_metrics['TP'] / (overall_metrics['TP'] + overall_metrics['FP']) if (overall_metrics['TP'] + overall_metrics['FP']) > 0 else 0\n",
    "#     overall_recall = overall_metrics['TP'] / (overall_metrics['TP'] + overall_metrics['FN']) if (overall_metrics['TP'] + overall_metrics['FN']) > 0 else 0\n",
    "#     overall_f1 = (2 * overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "#     overall_f5 = (26 * overall_precision * overall_recall) / (25 * overall_precision + overall_recall) if (25 * overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "#     # Print overall metrics\n",
    "#     print(f\"Overall Metrics:\")\n",
    "#     print(f\"TP: {overall_metrics['TP']}, FP: {overall_metrics['FP']}, FN: {overall_metrics['FN']}\")\n",
    "#     print(f\"Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}\")\n",
    "#     print(f\"F1 Score: {overall_f1:.4f}, F5 Score: {overall_f5:.4f}\")\n",
    "\n",
    "#     # Calculate and print category-wise metrics\n",
    "#     for category, metrics in category_metrics.items():\n",
    "#         precision = metrics['TP'] / (metrics['TP'] + metrics['FP']) if (metrics['TP'] + metrics['FP']) > 0 else 0\n",
    "#         recall = metrics['TP'] / (metrics['TP'] + metrics['FN']) if (metrics['TP'] + metrics['FN']) > 0 else 0\n",
    "#         f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "#         f5 = (26 * precision * recall) / (25 * precision + recall) if (25 * precision + recall) > 0 else 0\n",
    "\n",
    "#         print(f\"\\nCategory: {category}\")\n",
    "#         print(f\"TP: {metrics['TP']}, FP: {metrics['FP']}, FN: {metrics['FN']}\")\n",
    "#         print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "#         print(f\"F1 Score: {f1:.4f}, F5 Score: {f5:.4f}\")\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming df_true and df_test are already loaded\n",
    "# calculate_metrics(df_test, df_true)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
