{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary import\n",
    "import json\n",
    "import os\n",
    "from pipline import * \n",
    "from entitiy_parsing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE for Users:\n",
    "# 1. Navigate to input directory and change secret.json by providing your OpenAI API Key, Azure AI Language Key, and Azure Language Endpoint;\n",
    "# 2. Navigate to input directory and change input_text.json, this is the input JSON file you should provide. Example format is provided in the file;\n",
    "# 3. Provide the directory (folder name) you want to store the results generated from Azure and Fine-tuned GPT-4o-mini model below:\n",
    "azure_storage_directory = \"azure_output\"\n",
    "gpt_storage_directory = \"gpt_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n",
      "[\"John Doe's email is john.doe@example.com.\", 'Visit https://www.example.com for more info.']\n"
     ]
    }
   ],
   "source": [
    "# Load input JSON\n",
    "with open('input/input_text.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the keys and values\n",
    "identifier_list = list(data.keys())\n",
    "text_list = list(data.values())\n",
    "\n",
    "print(identifier_list[:6])\n",
    "print(text_list[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1: Azure AI Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, call the line below to send request for azure pii detection, the request infromation should be stored in azure_storage_directory\n",
    "process_texts(text_list, identifier_list, azure_storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, call the line below to retrieve result, and stores result in the specified directory\n",
    "# Wait for a few minutes to run (batch processing might need several minutes)\n",
    "check_jobs_and_retrieve_results(azure_storage_directory)\n",
    "# The result should be in a json file ends with _results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2: Fine-tuned GPT-4o-mini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'gpt_output/batch1' is ready.\n",
      "JSON data successfully saved to 'gpt_output/batch1\\gpt_result.json'.\n"
     ]
    }
   ],
   "source": [
    "# Call the line below to get the result\n",
    "extract_parse_store(text_list,identifier_list, gpt_storage_directory)\n",
    "# The result should be in a json file ends with _result.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
